##input {
##	tcp {
##		port => 5000
##	}
##}

## Add your filters / logstash plugins configuration here

##output {
##	elasticsearch {
##		hosts => "elasticsearch:9200"
##	}
##}


input {


##  file {
##    path => "/var/log/apache/access.log"
##    start_position => "beginning"
##    sincedb_path => "/dev/null"
##  }

  file {
    path => "/var/data/cars.csv"
    type => "csv"
    start_position => "beginning"
  }


}
 
filter {
##    grok {
##      match => { "message" => "%{COMBINEDAPACHELOG}" }
##    }
##    date {
##    match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
##  }
##  geoip {
##      source => "clientip"
##    }
##}

  csv {
    separator => ","
    columns => ["maker", "model", "mileage", "manufacture_year", "engine_displacement", "engine_power", "body_type", "color_slug", "stk_year", "transmission", "door_count", "seat_count", "fuel_type", "date_created", "date_last_seen", "price_eur"]
    }

    mutate {convert => ["mileage", "integer"] }
    mutate {convert => ["price_eur", "float"] }
    mutate {convert => ["engine_power", "integer"] }
    mutate {convert => ["door_count", "integer"] }
    mutate {convert => ["seat_count", "integer"] }


  }


output {
  elasticsearch { 
    hosts => ["http://elasticsearch:9200"] 
    index => "cars"
    document_type => "sold_cars"
  }
##  stdout {}

}